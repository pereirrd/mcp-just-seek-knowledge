# üìã Requisitos para Transformar em Servidor MCP

## O que √© necess√°rio

Para transformar este projeto RAG em um servidor MCP utiliz√°vel no Cursor, voc√™ precisa implementar os seguintes componentes:

---

## 1. üì¶ Depend√™ncias Adicionais

### Instalar SDK MCP para Python

```bash
# Op√ß√£o 1: Usando o pacote oficial (se dispon√≠vel)
pip install mcp

# Op√ß√£o 2: Implementa√ß√£o manual do protocolo MCP
# O MCP usa comunica√ß√£o JSON via stdio, ent√£o voc√™ pode implementar manualmente
# usando apenas bibliotecas padr√£o do Python
```

**Nota**: O protocolo MCP √© baseado em JSON-RPC 2.0 e comunica√ß√£o via stdio (stdin/stdout). Voc√™ pode implementar manualmente ou usar um SDK se dispon√≠vel.

---

## 2. üèóÔ∏è Estrutura do Servidor MCP

### Componentes Necess√°rios:

#### A. **Servidor Principal** (`src/mcp_server.py`)
- Implementa o protocolo MCP
- L√™ requisi√ß√µes JSON do `stdin`
- Processa chamadas de ferramentas
- Retorna respostas JSON no `stdout`
- Gerencia o ciclo de vida do servidor

#### B. **Ferramentas (Tools) a Expor**

1. **`ingest_document`**
   - **Descri√ß√£o**: Ingesta um documento PDF no sistema RAG
   - **Par√¢metros**:
     - `pdf_path` (string, obrigat√≥rio): Caminho para o arquivo PDF
   - **Retorno**: Status da ingest√£o (sucesso/erro)

2. **`search_documents`**
   - **Descri√ß√£o**: Busca documentos relevantes usando busca sem√¢ntica
   - **Par√¢metros**:
     - `question` (string, obrigat√≥rio): Pergunta ou query de busca
     - `k` (integer, opcional, padr√£o: 10): N√∫mero de resultados a retornar
   - **Retorno**: Lista de documentos relevantes com scores

3. **`ask_question`**
   - **Descri√ß√£o**: Faz uma pergunta completa usando RAG (busca + LLM)
   - **Par√¢metros**:
     - `question` (string, obrigat√≥rio): Pergunta do usu√°rio
   - **Retorno**: Resposta gerada pelo LLM baseada no contexto

#### C. **Recursos (Resources) Opcionais**

1. **`document_stats`**
   - **Descri√ß√£o**: Retorna estat√≠sticas sobre documentos armazenados
   - **Retorno**: N√∫mero de documentos, tamanho do banco, etc.

---

## 3. üìù Arquivo de Configura√ß√£o MCP

### Localiza√ß√£o do arquivo:
- **Op√ß√£o 1**: `~/.cursor/mcp.json` (configura√ß√£o global do Cursor)
- **Op√ß√£o 2**: `.cursor/mcp.json` na raiz do projeto (configura√ß√£o local)

### Estrutura do `mcp.json`:

```json
{
  "mcpServers": {
    "rag-system": {
      "command": "python",
      "args": [
        "/caminho/absoluto/para/projeto/src/mcp_server.py"
      ],
      "env": {
        "PDF_PATH": "/caminho/para/documento.pdf",
        "PGVECTOR_COLLECTION": "document_embeddings",
        "PGVECTOR_URL": "postgresql://postgres:postgres@localhost:5432/rag",
        "OPENAI_API_KEY": "sua_chave_api_openai",
        "OPENAI_EMBEDDING_MODEL": "text-embedding-3-small",
        "OPENAI_MODEL": "gpt-3.5-turbo"
      }
    }
  }
}
```

**Importante**: 
- Use caminhos absolutos no `args`
- Configure todas as vari√°veis de ambiente necess√°rias
- O Cursor carrega este arquivo automaticamente ao iniciar

---

## 4. üîå Protocolo MCP - Estrutura B√°sica

### Mensagens MCP seguem o padr√£o JSON-RPC 2.0:

#### Requisi√ß√£o (do Cursor para o servidor):
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "tools/call",
  "params": {
    "name": "ask_question",
    "arguments": {
      "question": "Qual √© o conte√∫do do documento?"
    }
  }
}
```

#### Resposta (do servidor para o Cursor):
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "Resposta gerada pelo LLM..."
      }
    ]
  }
}
```

### Handshake Inicial:

O servidor deve responder ao `initialize`:

```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "protocolVersion": "2024-11-05",
    "capabilities": {
      "tools": {}
    },
    "serverInfo": {
      "name": "rag-system",
      "version": "1.0.0"
    }
  }
}
```

### Listar Ferramentas Dispon√≠veis:

```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "tools": [
      {
        "name": "ingest_document",
        "description": "Ingesta um documento PDF no sistema RAG",
        "inputSchema": {
          "type": "object",
          "properties": {
            "pdf_path": {
              "type": "string",
              "description": "Caminho para o arquivo PDF"
            }
          },
          "required": ["pdf_path"]
        }
      },
      {
        "name": "search_documents",
        "description": "Busca documentos relevantes usando busca sem√¢ntica",
        "inputSchema": {
          "type": "object",
          "properties": {
            "question": {
              "type": "string",
              "description": "Pergunta ou query de busca"
            },
            "k": {
              "type": "integer",
              "description": "N√∫mero de resultados",
              "default": 10
            }
          },
          "required": ["question"]
        }
      },
      {
        "name": "ask_question",
        "description": "Faz uma pergunta completa usando RAG",
        "inputSchema": {
          "type": "object",
          "properties": {
            "question": {
              "type": "string",
              "description": "Pergunta do usu√°rio"
            }
          },
          "required": ["question"]
        }
      }
    ]
  }
}
```

---

## 5. üîß Implementa√ß√£o T√©cnica

### Estrutura B√°sica do Servidor:

```python
import sys
import json
import asyncio
from typing import Any, Dict

# Importar fun√ß√µes existentes
from ingest import ingest_pdf, load_pdf, get_chunks
from search import search_prompt, create_vector_store
from chat import generate_response_with_llm

class MCPServer:
    def __init__(self):
        self.tools = {
            "ingest_document": self.handle_ingest,
            "search_documents": self.handle_search,
            "ask_question": self.handle_ask
        }
    
    async def handle_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Processa requisi√ß√µes MCP"""
        method = request.get("method")
        params = request.get("params", {})
        request_id = request.get("id")
        
        if method == "initialize":
            return self.handle_initialize(request_id)
        elif method == "tools/list":
            return self.handle_list_tools(request_id)
        elif method == "tools/call":
            return await self.handle_tool_call(request_id, params)
        else:
            return self.error_response(request_id, -32601, "Method not found")
    
    def handle_initialize(self, request_id: int) -> Dict[str, Any]:
        """Responde ao handshake inicial"""
        return {
            "jsonrpc": "2.0",
            "id": request_id,
            "result": {
                "protocolVersion": "2024-11-05",
                "capabilities": {"tools": {}},
                "serverInfo": {
                    "name": "rag-system",
                    "version": "1.0.0"
                }
            }
        }
    
    def handle_list_tools(self, request_id: int) -> Dict[str, Any]:
        """Lista ferramentas dispon√≠veis"""
        return {
            "jsonrpc": "2.0",
            "id": request_id,
            "result": {
                "tools": [
                    {
                        "name": "ingest_document",
                        "description": "Ingesta um documento PDF no sistema RAG",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "pdf_path": {
                                    "type": "string",
                                    "description": "Caminho para o arquivo PDF"
                                }
                            },
                            "required": ["pdf_path"]
                        }
                    },
                    # ... outras ferramentas
                ]
            }
        }
    
    async def handle_tool_call(self, request_id: int, params: Dict[str, Any]) -> Dict[str, Any]:
        """Processa chamada de ferramenta"""
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        if tool_name in self.tools:
            try:
                result = await self.tools[tool_name](arguments)
                return {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": str(result)
                            }
                        ]
                    }
                }
            except Exception as e:
                return self.error_response(request_id, -32000, str(e))
        else:
            return self.error_response(request_id, -32601, f"Tool '{tool_name}' not found")
    
    async def handle_ingest(self, arguments: Dict[str, Any]) -> str:
        """Handler para ingest_document"""
        pdf_path = arguments.get("pdf_path")
        # Usar fun√ß√µes de ingest.py
        # ...
        return "Documento ingerido com sucesso"
    
    async def handle_search(self, arguments: Dict[str, Any]) -> str:
        """Handler para search_documents"""
        question = arguments.get("question")
        k = arguments.get("k", 10)
        # Usar fun√ß√µes de search.py
        # ...
        return "Resultados da busca"
    
    async def handle_ask(self, arguments: Dict[str, Any]) -> str:
        """Handler para ask_question"""
        question = arguments.get("question")
        # Usar generate_response_with_llm de chat.py
        return generate_response_with_llm(question)
    
    def error_response(self, request_id: int, code: int, message: str) -> Dict[str, Any]:
        """Gera resposta de erro"""
        return {
            "jsonrpc": "2.0",
            "id": request_id,
            "error": {
                "code": code,
                "message": message
            }
        }
    
    async def run(self):
        """Loop principal do servidor"""
        while True:
            line = await asyncio.get_event_loop().run_in_executor(
                None, sys.stdin.readline
            )
            if not line:
                break
            
            try:
                request = json.loads(line.strip())
                response = await self.handle_request(request)
                print(json.dumps(response), flush=True)
            except json.JSONDecodeError:
                continue
            except Exception as e:
                error_response = self.error_response(
                    None, -32700, f"Parse error: {str(e)}"
                )
                print(json.dumps(error_response), flush=True)

if __name__ == "__main__":
    server = MCPServer()
    asyncio.run(server.run())
```

---

## 6. ‚úÖ Checklist de Implementa√ß√£o

- [ ] Instalar depend√™ncias MCP (se usar SDK) ou implementar protocolo manualmente
- [ ] Criar `src/mcp_server.py` com implementa√ß√£o do servidor MCP
- [ ] Adaptar fun√ß√µes existentes (`ingest.py`, `search.py`, `chat.py`) para serem chamadas pelo servidor
- [ ] Criar arquivo `mcp.json` com configura√ß√£o do servidor
- [ ] Configurar vari√°veis de ambiente no `mcp.json`
- [ ] Testar servidor manualmente (enviar JSON via stdin)
- [ ] Verificar se o Cursor detecta o servidor (`cursor-agent mcp list`)
- [ ] Testar cada ferramenta atrav√©s do Cursor
- [ ] Adicionar tratamento de erros robusto
- [ ] Adicionar logs para debug (opcional)

---

## 7. üß™ Testando o Servidor

### Teste Manual (via terminal):

```bash
# Enviar requisi√ß√£o de inicializa√ß√£o
echo '{"jsonrpc":"2.0","id":1,"method":"initialize","params":{"protocolVersion":"2024-11-05","capabilities":{},"clientInfo":{"name":"test","version":"1.0.0"}}}' | python src/mcp_server.py

# Enviar requisi√ß√£o para listar ferramentas
echo '{"jsonrpc":"2.0","id":2,"method":"tools/list"}' | python src/mcp_server.py

# Enviar requisi√ß√£o para chamar ferramenta
echo '{"jsonrpc":"2.0","id":3,"method":"tools/call","params":{"name":"ask_question","arguments":{"question":"Teste"}}}' | python src/mcp_server.py
```

### Verificar no Cursor:

```bash
# Listar servidores MCP configurados
cursor-agent mcp list

# Verificar logs do Cursor para erros
# (logs geralmente em ~/.cursor/logs/)
```

---

## 8. üìö Recursos Adicionais

- **Documenta√ß√£o MCP**: https://modelcontextprotocol.io
- **Documenta√ß√£o Cursor MCP**: https://docs.cursor.com/pt-BR/context/mcp
- **Especifica√ß√£o JSON-RPC 2.0**: https://www.jsonrpc.org/specification
- **Exemplos de servidores MCP**: GitHub do ModelContextProtocol

---

## 9. ‚ö†Ô∏è Considera√ß√µes Importantes

1. **Comunica√ß√£o stdio**: Todo o protocolo funciona via stdin/stdout
2. **JSON-RPC 2.0**: O MCP usa JSON-RPC 2.0 como base
3. **Ass√≠ncrono**: Use `asyncio` para opera√ß√µes ass√≠ncronas (importante para chamadas de API)
4. **Vari√°veis de Ambiente**: Todas devem estar configuradas no `mcp.json`
5. **Caminhos Absolutos**: Use caminhos absolutos no `mcp.json`
6. **Banco de Dados**: PostgreSQL deve estar rodando antes de usar o servidor
7. **Tratamento de Erros**: Implemente tratamento robusto de erros
8. **Logs**: Considere adicionar logs para facilitar debug

---

## 10. üéØ Resumo Executivo

**O que voc√™ precisa fazer:**

1. **Criar servidor MCP** (`src/mcp_server.py`) que:
   - Implementa protocolo JSON-RPC 2.0 via stdio
   - Exp√µe 3 ferramentas: `ingest_document`, `search_documents`, `ask_question`
   - Integra com c√≥digo existente (`ingest.py`, `search.py`, `chat.py`)

2. **Configurar `mcp.json`** com:
   - Comando para executar o servidor
   - Vari√°veis de ambiente necess√°rias
   - Caminhos absolutos

3. **Testar** a integra√ß√£o com o Cursor

**Complexidade**: M√©dia-Alta (requer conhecimento de JSON-RPC e protocolos de comunica√ß√£o)

**Tempo estimado**: 4-8 horas para implementa√ß√£o completa e testes
